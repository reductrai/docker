# ================================================================================
# ReductrAI Docker Configuration
# ================================================================================
# Copy this file to .env and configure for your environment
# cp .env.example .env

# ================================================================================
# LICENSE (REQUIRED)
# ================================================================================
# Get your license key at https://reductrai.com/pricing
# Use RF-DEMO-2025 for trial/testing
REDUCTRAI_LICENSE_KEY=RF-DEMO-2025

# ================================================================================
# PROXY CORE CONFIGURATION
# ================================================================================
# Environment mode
NODE_ENV=production

# Compression settings
REDUCTRAI_COMPRESSION=true
REDUCTRAI_COMPRESSION_LEVEL=heavy  # Options: light|medium|heavy

# Proxy operation mode
PROXY_MODE=sample                  # Options: sample|store-only|forward-only
SAMPLE_RATE=0.1                    # 0.1 = 10% sampling (90% cost reduction)

# Forward destination (where to send sampled data)
FORWARD_TO=https://api.datadoghq.com

# ================================================================================
# BACKEND MONITORING SERVICE (REQUIRED FOR PRODUCTION)
# ================================================================================
# ReductrAI sits between your apps and your monitoring service to reduce costs.
# Configure the monitoring service you're currently paying for.
#
# How it works:
# - ReductrAI stores 100% of data locally (compressed, AI-queryable)
# - ReductrAI forwards only 10% to your monitoring service
# - Result: Same dashboards, 90% cost reduction
#
# Choose ONE backend that you want to reduce costs on:

# Datadog (recommended for most users)
DATADOG_API_KEY=your_datadog_api_key_here
DATADOG_ENDPOINT=https://api.datadoghq.com

# New Relic
NEW_RELIC_API_KEY=

# Prometheus (for remote write)
PROMETHEUS_ENDPOINT=

# OpenTelemetry
OTLP_ENDPOINT=

# ================================================================================
# AI QUERY SERVICE (OPTIONAL - PREMIUM FEATURE)
# ================================================================================
# Local LLM model for natural language queries
AI_MODEL=mistral                   # Options: mistral|llama2|codellama|phi3

# ================================================================================
# TIERED STORAGE CONFIGURATION
# ================================================================================
# Hot storage: Fast SSD, recent data (last 7 days), full-resolution
STORAGE_HOT_ENABLED=true
STORAGE_HOT_RETENTION_DAYS=7
STORAGE_HOT_PATH=/app/data/hot

# Warm storage: Standard disk, medium-term (8-30 days), aggregated
STORAGE_WARM_ENABLED=true
STORAGE_WARM_RETENTION_DAYS=30
STORAGE_WARM_PATH=/app/data/warm
STORAGE_WARM_AGGREGATION=5m          # Aggregate to 5-minute intervals

# Cold storage: S3/Archive, long-term (31-365 days), highly compressed
STORAGE_COLD_ENABLED=true
STORAGE_COLD_RETENTION_DAYS=365
STORAGE_COLD_PATH=/app/data/cold
STORAGE_COLD_AGGREGATION=1h          # Aggregate to 1-hour intervals

# Cold Storage Backend (Optional - choose one)
STORAGE_COLD_TYPE=local              # Options: local|s3|gcs|azure|redis|postgres

# AWS S3
S3_BUCKET=
S3_REGION=us-east-1
S3_ACCESS_KEY=
S3_SECRET_KEY=
S3_ENDPOINT=                         # Optional: for MinIO, Wasabi, DigitalOcean Spaces, etc.

# Google Cloud Storage
GCS_BUCKET=
GCS_PROJECT_ID=
GCS_CREDENTIALS_PATH=/app/config/gcs-credentials.json

# Azure Blob Storage
AZURE_STORAGE_ACCOUNT=
AZURE_STORAGE_KEY=
AZURE_CONTAINER=reductrai-cold

# Redis (for fast cold storage with TTL)
REDIS_HOST=
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_TTL_DAYS=365

# PostgreSQL (for queryable cold storage)
POSTGRES_HOST=
POSTGRES_PORT=5432
POSTGRES_DB=reductrai
POSTGRES_USER=
POSTGRES_PASSWORD=
POSTGRES_SCHEMA=cold_storage

# ================================================================================
# DATA RETENTION POLICIES
# ================================================================================
# Automatic cleanup of expired data
AUTO_CLEANUP_ENABLED=true
CLEANUP_SCHEDULE=0 2 * * *           # Daily at 2 AM (cron format)

# Compression for cold storage
COLD_COMPRESSION_ALGORITHM=zstd      # Options: zstd|gzip|lz4
COLD_COMPRESSION_LEVEL=9             # 1-9 (higher = better compression, slower)

# ================================================================================
# ADVANCED SETTINGS (OPTIONAL)
# ================================================================================
# Proxy server settings
REDUCTRAI_PORT=8080
REDUCTRAI_HOST=0.0.0.0

# Dashboard UI
VITE_API_URL=http://proxy:8080

# AI Query service
AI_QUERY_PORT=8081
LOCAL_LLM_ENDPOINT=http://ollama:11434

# Ollama settings
OLLAMA_HOST=http://ollama:11434

# ================================================================================
# RESOURCE LIMITS (DOCKER)
# ================================================================================
# CPU/Memory limits are configured in docker-compose.yml
# Defaults: 2 CPU cores, 2GB RAM limit, 1GB RAM reservation
