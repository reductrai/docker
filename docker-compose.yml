services:
  # ReductrAI Proxy - Main service
  proxy:
    extends:
      file: ../deploy/config/services/docker-compose.services.yml
      service: proxy

  # Ollama LLM Service
  ollama:
    extends:
      file: ../deploy/config/services/docker-compose.services.yml
      service: ollama

  # AI Query Service (Optional - for local LLM)
  ai-query:
    extends:
      file: ../deploy/config/services/docker-compose.services.yml
      service: ai-query

networks:
  reductrai:
    driver: bridge

volumes:
  reductrai-data:
    driver: local
  ai-models:
    driver: local
  ollama-data:
    driver: local
